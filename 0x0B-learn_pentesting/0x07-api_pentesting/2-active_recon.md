# active reconnaissance
*  process of interacting directly with the target primarily through the use of scanning
* use your recon to search for your target's APIs and any useful information
* idea is to scan systems, enumerate open ports and find ports that have services using HTTP
    - once found, the systems hosting HTTP and/or web application can be investigated using a web browser
    - you could find an API being advertised to end users or you may have to dig deeper
    - you can scan the web app for API-related directories
* TLDR:  build out the target's API attack surface using these tools among others: nmap, OWASP Amass, gobuster, kiterunner and devtools
### nmap
* nmap is a powerful tool for scanning ports, searching for vulnerabilities, enumerating services and discovering live hosts
* run two Nmap scans in particular: general detection and all port
     - nmap general detection scan uses default scripts `-sC` and service enumeration `-sV` against a target then saves the output in three formats for later review (`-oX` for XML, `-oN` for nmap, `-oG` for greppable or `-oA` for all three)

    ```bash
        nmap -sC -sV [target address or network range] -oA nameofoutput
    ```

* nmap all-port-scan checks all 65,535 TCP ports for running services, application versions and host operating system in use

    ```bash
        nmap -p- [target address] -oA allportscanresults
    ```

* as soon as the general detection scan begins returning results, kick off the all-port scan
    - begin your hands-on analysis of the results
    - you will most likely discover APIs by looking at the results related to HTTP traffic and other indications of web servers
    - typically, you will find these running on ports 80 and 443 but an API can be hosted on all sorts of different ports
    - once you discover a web server, you can perform HTTP enumeration using a nmap NSE script (use -p to specify which ports you'd like to test)

        ```bash
            nmap -sV --script=http-enum <target> -p 80,443,8000,8080
        ```

### OWASP Amass
* a command-line tool that can map a target’s external network by collecting OSINT from over 55 different sources
* you can set it to perform passive or active scans
    - if you choose the active option, Amass will collect information directly from the target by requesting its certificate information, otherwise, it collects data from search engines (such as google, bing and hackerOne), SSL certificate sources (such as googleCT, censys and facebookCT), search APIs (such as shodan, alienVault, cloudflare, and gitHub) and the web archive wayback
##### making the most of Amass with API Keys
* before diving into using Amass, we should make the most of it by adding API keys to it
    1. we can see which data sources are available for Amass (paid and free) by running

        ```bash
            amass enum -list
        ```

    2. create a config file to add our API keys to

        ```bash 
            sudo curl https://raw.githubusercontent.com/OWASP/Amass/master/examples/config.ini >~/.config/amass/config.ini
        ```

    3. update the `config.ini`; here we add API keys with Censys. simply visit [this site][def] and register a free account. make sure to use a valid email because you will have to verify for access to your free account

    4. once you have obtained your API id and secret, edit the `config.ini` file and add the credentials to the file

        ```bash
            sudo nano ~/.config/amass/config.ini
        ```

> **as with any credentials make sure not to share them. if you did share them then simply use the `Reset My API Secret` button back on [censys.io][def]. you can repeat this process with many free accounts and API keys then you will make OWASP Amass into a powerhouse for API reconnaissance**

    ```bash
        amass enum -active -d target-name.com |grep api
    ```

    ```text
        ---example output---
        legacy-api.target-name.com
        api1-backup.target-name.com
        api3-backup.target-name.com
    ```

* this scan could reveal many unique API subdomains including `legacy-api.target-name.com`
    - an API endpoint named `legacy` could be of particular interest because it seems to indicate an improper asset management vulnerability
* Amass has several useful command-line options
    - use the `intel` command to collect SSL certificates, search reverse Whois records and find ASN IDs associated with your target: start by providing the command with target IP addresses

        ```bash
            amass intel -addr [target IP addresses]
        ```

    - if this scan is successful, it will provide you with domain names: said domains can then be passed to `intel` with the `whois` option to perform a reverse *whois* lookup

        ```bash
            amass intel -d [target domain] –whois
        ```

    - this could give you a lot of results; focus on the interesting results that relate to your target organisation
    - once you have a list of interesting domains, upgrade to the enum subcommand to begin enumerating subdomains
    - if you specify the `passive` option, Amass will refrain from directly interacting with your target

        ```bash
            amass enum -passive -d [target domain]
        ```

    - the active enum scan will perform much of the same scan as the passive one but it will add domain name resolution, attempt DNS zone transfers and grab SSL certificate information

        ```bash
            amass enum -active -d [target domain]
        ```

    - add the `brute` option to brute-force subdomains, `w` to specify the `API_superlist` wordlist and then the `dir` option to send the output to the directory of your choice

        ```bash
            amass enum -active -brute -w /usr/share/wordlists/API_superlist -d [target domain] -dir [directory name]
        ```  

### directory brute-force with gobuster
* gobuster can be used to brute-force URIs and DNS subdomains from the command line
    - if you prefer a graphical user interface, check out OWASP’s dirbuster
* in gobuster, you can use wordlists for common directories and subdomains to automatically request every item in the wordlist and send them to a web server and filter the interesting server responses
* the results generated from gobuster will provide you with the URL path and the HTTP status response codes
     - you can brute-force URIs with burp suite’s intruder, however, burp community cdition is much slower than gobuster
* whenever you are using a brute-force tool, you will have to balance the size of the wordlist and the length of time needed to achieve results
     - kali has directory wordlists stored under `/usr/share/wordlists/dirbuster` that are thorough but will take some time to complete
     - instead, you can use an API-related wordlist which will speed up your gobuster scans since the wordlist is relatively short and only contains directories related to APIs
* the following example uses an API-specific wordlist to find the directories on an IP address

    ```bash
        gobuster dir -u target-name.com:8000 -w /home/hapihacker/api/wordlists/common_apis_160
    ```

    - sample ouptput viz:

    ```text
        ========================================================

        gobuster

        by OJ Reeves (@TheColonial) & Christian Mehlmauer (@firefart)

        ========================================================

        [+] Url:                     http://192.168.195.132:8000
        [+] Method:                  GET
        [+] Threads:                 10
        [+] Wordlist:                /home/hapihacker/api/wordlists/common_apis_160
        [+] Negative Status codes:   404
        [+] User Agent:              gobuster
        [+] Timeout:                 10s

        ========================================================

        09:40:11 Starting gobuster in directory enumeration mode

        ========================================================

        /api                (Status: 200) [Size: 253]
        /admin                (Status: 500) [Size: 1179]
        /admins               (Status: 500) [Size: 1179]
        /login                (Status: 200) [Size: 2833]
        /register             (Status: 200) [Size: 2846]
    ```

* once you find API directories, say, the `/api` directory shown in this output either by crawling or brute force, you can use burp to investigate them further
    - gobuster has additional options; list them using the `h` option

        ```bash
            gobuster dir -h
        ```

    - if you would like to ignore certain response status codes, use the option `b`
    - if you would like to see additional status codes, use `x`
    - you could enhance a gobuster search with the following

        ```bash
            gobuster dir -u ://targetaddress/ -w /usr/share/wordlists/api_list/common_apis_160 -x 200,202,301 -b 302
        ```

    - gobuster provides a quick way to enumerate active URLs find API paths
 ### kiterunner
* is currently (Fri, 05 Oct, 2024, 0747h) the best tool available for discovering API endpoints and resources
* while directory brute force tools like gobuster and dirbuster work to discover URL paths, it typically relies on standard HTTP `GET` requests; kiterunner will not only use more HTTP request methods common with APIs (`GET`, `POST`, `PUT` and `DELETE`) but also mimic common API path structures
* in other words, instead of requesting `GET /api/v1/user/create`, kiterunner will try `POST /api/v1/user/create`; that is, mimicking a more realistic request
* you can perform a quick scan of your target’s URL or IP address viz

    ```bash
        kr scan HTTP://127.0.0.1 -w ~/api/wordlists/data/kiterunner/routes-large.kite
    ```

 * kiterunner will provide you with a list of interesting paths; the fact that the server is responding uniquely to requests to certain paths, for example, `/api/` paths indicates that the API exists
* scans can be conducted w/o authorisation headers even f the target requires them
* if you want to use a text wordlist instead of a `.kite` file, use the brute option with the text file of your choice

    ```bash
        kr brute <target> -w ~/api/wordlists/data/automated/nameofwordlist.txt
    ```

    - if you have many targets, you can save a list of line-separated targets as a text file and use that file as the target
    - you can use any of the following line-separated URI formats as input

        ```text
            Test.com
            Test2.com:443
            http://test3.com
            http://test4.com
            http://test5.com:8888/api
        ```

* another kiterunner feature is the ability to replay requests
    - not only will you have an interesting result to investigate, you will also be able to dissect exactly why that request is interesting
    - in order to replay a request, copy the entire line of content into kiterunner, paste it using the kb replay option and include the wordlist you used

        ```bash
            kr kb replay "GET     414 [    183,    7,   8]
            ://192.168.50.35:8888/api/privatisations/count 0cf6841b1e7ac8badc6e237ab300a90ca873d571" -w
            ~/api/wordlists/data/kiterunner/routes-large.kite
        ```

    - running this will replay the request and provide you with the HTTP response
    - you can then review the contents to see if there is anything worthy of investigation
    - suggestion: review interesting results and then pivot to testing them using postman and burp suite
### devtools
* devtools contains some underrated web application hacking tools
* the following steps will help you easily and systematically filter through thousands of lines of code in order to find sensitive information in page sources
     1. open your target page
     2. open devtools with `F12` or `ctrl-shift-I`
     3. adjust the devtools window until you have enough space to work with
     4. select the `Network` tab
     5. refresh the page (`CTRL+r`)
* you can use the `filter` tool to search for any term  such as "API", "v1" or "graphql"
     - this is a quick way to find API endpoints in use
     - have the devtools `Network` tab open while you perform actions on the web page, for example, while you authenticate to an API
     - you should see a new request pop up: at this point, you can dive deeper into the request by right-clicking on one of the requests and selecting `Edit and Resend`
    - this will allow you to check out the request in the browser, edit the headers/request body and send it back to the API provider
    - although this is a great devtools feature, you may want to move into a browser that was meant for interacting with APIs: postman
    - you can use devtools to migrate individual requests over to postman using cURL
    - once you have copied the desired request, open postman
    - select `Import` and click on the `Raw text` tab
    - paste in the cURL request and select `import`
    - once the request has been imported it will have all of the necessary headers and the request body necessary to make additional requests in postman: this is a great way to quickly interact with an API and interact with a single API request
### summary
* reconnaissance is quite important when testing APIs
* discovering API endpoints is a necessary first step when attacking APIs
* good recon also has the added benefit of potentially providing you with the keys to the castle in the form of API keys, passwords, tokens and other useful information disclosures

[def]: https://censys.io/register